# News Feed System Design (Step-by-Step Build-Up)

## 1. Start From the User Experience (Always First)

Before architecture, ask:

>
> What does the user expect when they open the app?
> 

From a userâ€™s point of view:

* I open the app
* I immediately see a list of posts
* Posts are:
    * From people I follow
    * Ordered sensibly (latest or relevant)

* Scrolling feels infinite
* New posts appear after some time

This defines the product behavior, not the tech.


## 2. Define the Core Problem (In One Line)

> Given a user, efficiently show a personalized, ordered list of posts from people they follow.
>

That's it. Everything else is a consequence of this sentence.


## 3. Identify the Fundamental Asymmetry (Critical Insight)

Now ask:

>
> Do users read feeds more often, or create posts more often?
> 

Reality (for almost all social apps):

* Feed reads: **very frequent**
* Post creation: **infrequent**

Typical ratio:

```text
Reads : Writes â‰ˆ 100 : 1
```

This single fact drives the entire design.

Conclusion:
ðŸ‘‰ We must optimize for fast reads, even if writes become more complex.


## 4. Break the System Into Conceptual Pieces

Before tech, identify logical responsibilities:

**1. Post creation**
  * User creates content

**2. Follow graph**
  * Who follows whom

**3. Feed generation**
  * Which posts appear in whose feed

**4. Feed storage**
  * Where the feed lives

**5. Feed retrieval**
  * How the feed is served fast

We will now design each piece in order.


## 5. Start With the Simplest Possible Model (Baseline)

Naive idea (important to say in interviews)

> When a user opens the feed:
> * Get all people they follow
> * Fetch recent posts from each
> * Merge and sort
> 

This is called **fan-out on read**.

**Why this fails at scale**

If a user follows 500 people:

* 500 queries
* Huge merge + sort
* Slow response
* Terrible latency

Conclusion: <br>
âŒ Real-time merging does not scale.


## 6. Flip the Thinking: Precompute the Feed

Instead of doing work at read time:

>
> Do the work earlier, when a post is created.
> 

This leads to the key idea:

>
> When a user creates a post, push it into followersâ€™ feeds.
> 

This is called **fan-out on write**.


## 7. Understand Fan-out on Write (Carefully)

**What happens when Alice posts?**

1. Alice creates a post
2. We find Alice's followers
3. For each follower:
    * Insert this post into their feed list

Now when Bob opens the app:
 * Bob's feed is already prepared
 * Just read and return

**Reads become extremely fast.**


## 8. First Real Architecture Emerges

Now the system naturally splits:

* Post Service â€“ handles post creation
* Feed Service â€“ handles feed storage & retrieval
* Follow Service â€“ manages follower relationships

At a high level:

```text
User -> Post Service -> Feed System -> User Feed
```

But we still need to make this scalable.


## 9. Introduce Asynchrony (Very Important)

Fan-out on write can be expensive.

So we **never do it synchronously**.

Instead:

1. Save the post
2. Publish a "post created" event
3. Background workers do fan-out

This gives:

* Fast post creation
* Retryability
* Fault tolerance


## 10. Event-Driven Fan-out

We now introduce an event bus (Kafka-like).

**Write path**

```text
User creates post
    |
    v
Post Service (store post)
    |
    v
Publish PostCreated event
    |
    v
Fanout Workers    
```

Workers are responsible for updating feeds.


## 11. Feed Storage Model (Key Design Choice)

We need per-user feed storage.

Simple and effective model:

```text
feed:userId = [postId1, postId2, postId3, ...]
```

Characteristics:

* Ordered list (latest first)
* Append-only
* Bounded (e.g., last 1000 posts)


## 12. Where Do We Store the Feed?

Two-tier approach:

**Hot storage**

* Redis
* Fast reads
* Stores recent feed items

**Cold / durable storage**

* Cassandra / DynamoDB
* Stores older feed items

This balances:

* Speed
* Cost
* Durability


13. Feed Read Path (Now Very Simple)

When user opens feed:

```text
Client
  |
  v
Feed Service
  |
  v
Read feed:userId from Redis
  |
  v
Fetch post metadata
  |
  v
Return response
```

Latency:

* Redis read: 1â€“2 ms
* Overall: <100 ms

This is why we chose fan-out on write.


## 14. The Celebrity Problem (Inevitable)

Now ask the dangerous question:

>
> What if a user has **10 million followers**?
> 

Fan-out on write becomes impossible:

* 10 million writes per post
* System collapse

So we must treat such users differently.


## 15. Hybrid Fan-out Strategy (Production Reality)

We classify users:

* Normal users â†’ fan-out on write
* Celebrity users â†’ fan-out on read

Threshold example:

```text
followers > 100k => celebrity
```

**This is not optional at scale.**


## 16. How Celebrity Posts Are Handled

For celebrity users:

* Their posts are NOT pushed to followers feeds
* Instead:
    * Stored normally
    * Pulled and merged at read time

So feed read becomes:

```text
precomputed feed
+ celebrity posts
```

Merged and sorted.


## 17. Pagination (Must Be Cursor-Based)

We never use offset pagination.

Correct approach:

```text
GET /feed?cursor=lastSeenPostId&limit=20
```

Benefits:

* No duplicates
* Stable ordering
* Works with changing feeds


## 18. Ordering and Ranking (Start Simple)

Initial system:

* Reverse chronological order

Later enhancement:

* Ranking score based on:
    * Recency
    * Engagement
    * User affinity

Ranking logic can evolve independently.


## 19. Consistency Model (Be Explicit)

This system is:

* Eventually consistent
* New post may appear after seconds
* This is acceptable for feeds

Strong consistency would destroy scalability.

---

## How to: Fan-out on Write

W'll now zoom into fan-out on write and walk through it mechanically, 
with numbers, concrete examples, and zero assumptions.

W'll do this in three phases:

1. Fan-out on write (how feeds are built)
2. Feed read: merge + sort (what user actually sees)
3. Pagination: how next page is fetched safely

No shortcuts, no "and then magic happens".


### Part 1: Feed Creation

### Step 1: Define the Actors

We'll use real users so nothing is abstract.

**Users**

* Alice (userId = 1) â†’ creates posts
* Bob (userId = 2) â†’ follows Alice
* Carol (userId = 3) â†’ follows Alice
* Dave (userId = 4) â†’ does NOT follow Alice

**Follow Graph**

```text
Alice -> followers = [Bob, Carol]
```

---

### Step 2: Define What a "Post" Actually Is

When Alice creates a post, we **separate two things**:

1. Post object (content)
2. Feed references (who sees it)

**Post object (stored once)**

```text
{
  "postId": 9001,
  "authorId": 1,
  "content": "Hello world",
  "createdAt": 1700000000
}
```

Stored in Post DB (MySQL / Cassandra / etc).

This object is **never duplicated**.

---

### Step 3: Alice Creates a Post (Write Path)

#### Step 3.1 â€“ Synchronous part

Alice clicks â€œPostâ€.

The Post Service does:

1. Validate request
2. Insert post into Post DB
3. Publish an event

```text
PostCreated {
  postId: 9001
  authorId: 1
  createdAt: 1700000000
}
```



At this point:

* Alice's request is done
* No feed updates yet
* No followers touched


### Step 4: Fan-out Worker Consumes the Event

This is asynchronous.

Fan-out Worker receives:

```text
PostCreated(postId=9001, authorId=1)
```


### Step 5: Worker Fetches Followers

Worker calls Follow Service:

```text
getFollowers(authorId=1)
â†’ [2, 3]  // Bob, Carol
```

Important:

* Dave is not included
* Followers list is authoritative


### Step 6: Worker Updates Each Followerâ€™s Feed

**Feed storage model (critical)**

Each user has a **feed list**:

```text
feed:{userId} = ordered list of postIds
```

Stored in Redis / Cassandra.

#### Step 6.1 â€“ Insert for Bob

```text
feed:2 (Bob)
```

Before:

```text
[8005, 7999, 7990]
```

Insert Aliceâ€™s post **at the head**:

```text
[9001, 8005, 7999, 7990]
```

#### Step 6.2 â€“ Insert for Carol

```text
feed:3 (Carol)
```

Before:

```text
[8010, 8008]
```

After:

```text
[9001, 8010, 8008]
```

#### Step 6.3 â€“ Dave's feed

Dave does not follow Alice.

```text
feed:4
```

Unchanged.

### Step 7: What We Achieved

At the end of fan-out:

* Post stored once
* Feed references stored per follower
* No work needed at read time

This is the entire point of fan-out on write.


### Part 2: Feed Read â€“ Merge and Sort (Step by Step)

Now Bob opens the app.

### Step 8: Bob Requests His Feed

API call:

```text
GET /feed?limit=3
```

### Step 9: Feed Service Fetches Bob's Feed List

From Redis:

```text
feed:2 = [9001, 8005, 7999, 7990]
```

These are post IDs only, already ordered.

No sorting needed yet.


### Step 10: Fetch Post Objects

Feed Service now fetches metadata for these IDs:

```text
SELECT * FROM posts
WHERE postId IN (9001, 8005, 7999)
```

Result:

| postId | author | createdAt |
|--------|--------|-----------|
| 9001   | Alice  | T=10      |
| 8005   | Eve    | T=9       |
| 7999   | Frank  | T=8       |


### Step 11: Do We Need to Sort?

Answer: usually no.

Why?

* Feed list was pre-ordered
* Insertions were always at the head
* Order is already chronological

Sorting is only needed if:

* We merge multiple sources (celebrities, ads)
* We apply ranking logic

For now:

```text
Final feed order = feed list order    
```

### Step 12: Return Response

```text
{
  "items": [
    { "postId": 9001, "author": "Alice" },
    { "postId": 8005, "author": "Eve" },
    { "postId": 7999, "author": "Frank" }
  ],
  "nextCursor": "7999"
}
```

Bob sees Alice's post immediately.


### Part 3: Pagination â€“ Fetching the Next Page (Correctly)

This is where many designs break.

### Step 13: Why Offset Pagination Is Wrong

Bad API:

```text
GET /feed?page=2
```

Why it fails:

* New posts arrive
* Items shift
* Duplicates or missing posts


### Step 14: Cursor-Based Pagination (Correct)

We use postId or timestamp as cursor.

From previous response:

```text
nextCursor = 7999
```

### Step 15: Bob Requests Next Page

```text
GET /feed?limit=3&cursor=7999
```

Meaning:

>
> "Give me posts after postId 7999."
>

### Step 16: Feed Service Applies Cursor

From Bobâ€™s feed list:

```text
feed:2 = [9001, 8005, 7999, 7990, 7980]
```

We drop everything up to and including cursor:

```text
Remaining = [7990, 7980]
```

Take next 3 (or fewer):

```text
[7990, 7980]
```

### Step 17: Fetch Metadata and Respond

```text
{
  "items": [
    { "postId": 7990 },
    { "postId": 7980 }
  ],
  "nextCursor": "7980"
}
```

* No duplicates.
* No missing posts.
* Order preserved.

### Important Observations (Memorize These)

* Fan-out on write moves work from read to write
* Feeds store references, not full posts
* Ordering is decided at insertion time
* Reads are simple list lookups
* Pagination uses cursors, not offsets


### One-Paragraph Interview Explanation (Exact)

In fan-out on write, when a user creates a post, we asynchronously push the post ID into 
each follower's feed list. Each userâ€™s feed is stored as an ordered list of post IDs, 
typically in Redis. This makes feed reads extremely fast because no merging or sorting
is required at request time. When a user opens the feed, we read the precomputed list, 
fetch post metadata, and return results. Pagination is handled using cursor-based pagination
on post IDs or timestamps to avoid duplicates and missing items as the feed changes.


## Celebrity Case: Fan-out on Read (Step by Step)

Now we'll do exactly the same mechanical walk-through, but for the celebrity case.

We will reuse the same mental model, but **change one variable**:
the author is a **celebrity**.


### Step 1: Define the Actors (Concrete)

**Users**

* Alice (userId = 1) â†’ celebrity
* Bob (userId = 2) â†’ follower
* Carol (userId = 3) â†’ follower
* Dave (userId = 4) â†’ follower

**Scale difference (this is the key)**

```text
Alice followers = 5,000,000
```

This is what breaks normal fan-out on write.

---

### Step 2: Define the Celebrity Rule (Explicit)

We define a system rule:

```text
If followerCount > 100,000
â†’ user is treated as CELEBRITY
```

This decision is:

* deterministic
* cached
* checked at post creation time

---

### Step 3: What Changes for a Celebrity?

**Normal user**

* Push postId into every followerâ€™s feed (fan-out on write)

**Celebrity**

* **DO NOT push to follower feeds**
* Store post normally
* Followers will pull it later (fan-out on read)

This avoids millions of writes per post.

---

### Step 4: Alice (Celebrity) Creates a Post

**Post object (same as before)**

```text
{
  "postId": 9100,
  "authorId": 1,
  "content": "New movie trailer!",
  "createdAt": 1700001000
}
```

Stored once in Post DB.

---

### Step 5: PostCreated Event Is Published

```text
PostCreated {
  postId: 9100
  authorId: 1
  createdAt: 1700001000
}
```

### Step 6: Fan-out Worker Receives the Event

Worker logic now diverges.

#### Step 6.1 â€“ Worker checks author type

```text
isCelebrity(authorId=1) â†’ true
```

---

### Step 7: Worker Behavior for Celebrity Post

**What the worker does**

* âŒ Does NOT fetch followers
* âŒ Does NOT update any feed lists
* âœ… Stores postId in celebrity timeline

Example storage:

```text
celebrity_posts:1 = [9100, 9090, 9080, ...]
```

This list is:

* ordered by time
* short (e.g., last 1000 posts)
* append-only

---

### Step 8: What Exists After Write Phase

At this point:

**Post DB**

```text
post 9100 exists
```

**Celebrity timeline**

```text
celebrity_posts:1 = [9100, 9090, ...]
```

**Bob / Carol / Dave feeds**

```text
feed:2 (Bob)   â†’ unchanged
feed:3 (Carol) â†’ unchanged
feed:4 (Dave)  â†’ unchanged
```

**No fan-out happened.**

This is intentional.


### Now the Read Path (This Is Where Work Happens)


### Step 9: Bob Opens His Feed

API call:

```text
GET /feed?limit=5
```

---

### Step 10: Feed Service Fetches Bob's Precomputed Feed

From Redis:

```text
feed:2 = [9001, 8005, 7999, 7990]
```

These came from **normal users only**.

---

### Step 11: Feed Service Fetches Bob's Follow List

```text
getFollowees(userId=2)
â†’ [Alice(1), Eve(5), Frank(6)]
```

---

### Step 12: Filter Celebrity Followees

From follow list:

```text
Celebrities followed by Bob = [Alice]
```

---

### Step 13: Fetch Celebrity Posts

For Alice:

```text
celebrity_posts:1 = [9100, 9090, 9080]
```

We only take recent posts (bounded).

---

### Step 14: Merge Normal Feed + Celebrity Posts

**Inputs**

Normal feed:

```text
[9001, 8005, 7999, 7990]
```

Celebrity posts:

```text
[9100, 9090]
```

---

### Step 15: Merge by Time (Explicit)

Each post has `createdAt`.

We now do a **k-way merge** (small k):

| postId | source    | createdAt |
|--------|-----------|-----------|
| 9100   | celebrity | T=12      |
| 9001   | normal    | T=11      |
| 9090   | celebrity | T=10      |
| 8005   | normal    | T=9       |
| 7999   | normal    | T=8       |

Resulting order:

```text
[9100, 9001, 9090, 8005, 7999]
```

---

### Step 16: Apply Limit

Limit = 5

```text
Final feed = [9100, 9001, 9090, 8005, 7999]
```

---

### Step 17: Return Response With Cursor

Cursor is the last itemâ€™s timestamp or ID:

```text
{
  "items": [...],
  "nextCursor": {
    "lastTimestamp": 1700000800
  }
}
```

---

### Pagination With Celebrity Posts (Important)


### Step 18: Bob Requests Next Page

```text
GET /feed?limit=5&cursor=1700000800
```

Meaning:
>
> "Give me posts older than this timestamp."
> 

### Step 19: Apply Cursor Separately

**Normal feed**

Drop items newer than cursor.

**Celebrity feed**

Drop items newer than cursor.

Now merge again.

This guarantees:

* No duplicates
* No missing celebrity posts

---

#### Why This Design Works

**Write Path**

* Celebrity post = O(1) work
* No write amplification

Read Path

* Slightly more expensive
* Only affects users who follow celebrities
* Bounded merge size

This matches real usage patterns.


### Side-by-Side Summary (Memorize)

| Aspect          | Normal User  | Celebrity       |
|-----------------|--------------|-----------------|
| Fan-out         | On write     | On read         |
| Writes per post | O(followers) | O(1)            |
| Read cost       | Very low     | Moderate        |
| Feed storage    | Per user     | Shared timeline |


### One-Paragraph Interview Explanation (Exact)

For celebrity users, fan-out on write is infeasible due to massive follower counts. 
Instead, we store celebrity posts separately and perform fan-out on read. 
When a follower requests their feed, we merge their precomputed feed with recent 
posts from followed celebrities, sorting by timestamp. This shifts work to read 
time only for affected users, avoids write amplification, and keeps the system scalable.

